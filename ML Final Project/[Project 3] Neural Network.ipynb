{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Project 3] 10 digits classification - Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by **loading** our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pd.read_csv('features.txt')\n",
    "labels = pd.read_csv('labels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated in the subject it is necessary to **replace** the \"10\" with 0 in the dataset. <br>\n",
    "To do this we use the function `replace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.rename(columns = {'10' : 'actual_value'}, inplace = True)\n",
    "labels.replace(10,0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the `scikit learn` method called `train_test_split` to split the datas into a **train** and a **test** set <br>\n",
    "Here we're using a test set representing 20% of our dataset. <br>\n",
    "this method automaticaly suffles the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image, labels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train.actual_value)\n",
    "y_test = pd.get_dummies(y_test.actual_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the neural network, the number of nodes for each layer (input, hidden, output)must be given.<br>\n",
    "After those informations, the constructor will initialize various things : \n",
    "* A Matrix of weights from input to hidden layer : `weight_ih`\n",
    "* A Matrix of weights from hidden to output layer : `weight_ho`\n",
    "* A Matrix of bias for the hidden layer : `bias_h`\n",
    "* A Matrix of bias for the output layer : `bias_o`\n",
    "* A learning initialized abitrary : `learningRate`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and score method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three main methods to implement:\n",
    "* feedforward: a function that will permit to obtain a prediction from a single input of the 400 pixels\n",
    "* train: A method that will take the input images and their labels from the train set as argument, considering we are doing supervised learning\n",
    "* score: A method that will take the input images and their labels from the test set as argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedforward method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to implement the feedforward method. <br>\n",
    "To do that we need to calculate the activations of the hidden and the output layers. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Hiden \\, Layer =  \\sigma \\, (weight\\_ih . Input \\, layer + bias\\_h)$ <br>\n",
    "$Output \\, Layer =  \\sigma \\, (weight\\_ho . Input \\, layer + bias\\_o)$ <br>\n",
    "> Where $\\sigma$ represents the sigmoid function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll take the output layer's activations as the output of this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we need to implement the train function. <br>\n",
    "we begin by computing the errors of the output (`output_errors`) and the hidden (`hidden_errors`) layers by those formulas :  <br>\n",
    "\n",
    "$Output\\_errors = labels - outputs$ <br>\n",
    "$Hidden\\_errors = weight\\_ho^t . Output\\_errors$\n",
    "\n",
    "> Here the `.` represents a matricial product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the errors for each layers we can compute the **gradients** in order to obtain the value by which we are going to correct our **weights** (`weight_ih_deltas` and `weight_ho_deltas`)  and **biases** (`hidden_gradients` and `output_gradients`). <br>\n",
    "To do this we will use linear regression formulas ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Weight\\_ho\\_deltas  = learning\\, rate \\times output\\_errors \\, \\times \\, \\sigma'(Output \\, Layer) \\, . \\, Hiden \\, Layer \\, ^t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Weight\\_ih\\_deltas  = learning\\, rate \\times hidden\\_errors \\, \\times \\, \\sigma'(hidden \\, activation) \\, . \\, Input \\, Layer \\, ^t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$hidden\\_gradients  = learning\\, rate \\times hidden\\_errors \\, \\times \\, \\sigma'(Hiden \\, Layer)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$output\\_gradients  = learning\\, rate \\times output\\_error \\, \\times \\, \\sigma'(Input \\, Layer)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here $\\sigma'$ reprensents the derivative of the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of the train method is to **update** our variables by adding the gradient we just calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$weight\\_ih = weight\\_ih + Weight\\_ih\\_deltas$<br>\n",
    "$weight\\_ho = weight\\_ho + Weight\\_ho\\_deltas$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$bias\\_h = bias\\_h + hidden\\_gradients$ <br>\n",
    "$bias\\_o = bias\\_o + output\\_gradients$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score method permits to compute the **accuracy** of the model on a train set <br>\n",
    "To do that we're just taking the **maximum value** of our outputs and stating that it's our predicted value <br>\n",
    "Then we build an array that compares `actual` and `predicted` value.\n",
    "We add a **one** to the array if the predicted value is equal to the actual one and **zero** if not <br>\n",
    "\n",
    "After that we just have to return following result:\n",
    "\n",
    "$Accuracy = \\frac{one's \\, occurences}{array's \\, size}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "def dsigmoid(X):\n",
    "    return sigmoid(X) * (1 - sigmoid(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, nb_input_nodes, nb_hiden_nodes, nb_output_nodes):\n",
    "        \n",
    "        #Seting each layer size\n",
    "        self.nb_input_nodes = nb_input_nodes\n",
    "        self.nb_hiden_nodes = nb_hiden_nodes\n",
    "        self.nb_output_nodes = nb_output_nodes\n",
    "        \n",
    "        #Seting weight matrix\n",
    "        self.weight_ih = np.random.rand(self.nb_hiden_nodes, self.nb_input_nodes)\n",
    "        self.weight_ho = np.random.rand(self.nb_output_nodes, self.nb_hiden_nodes)\n",
    "        \n",
    "        #Seting learningRate\n",
    "        self.learningRate = 0.7\n",
    "        \n",
    "        #Seting Bias\n",
    "        self.bias_h = np.random.rand(nb_hiden_nodes, 1)*5\n",
    "        self.bias_o = np.random.rand(nb_output_nodes, 1)*5\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    # input must have (nb_input_nodes, 1) as shape\n",
    "    def feedforward(self, input):\n",
    "        self.z_hiden_activation = np.dot(self.weight_ih, input)\n",
    "        self.z_hiden_activation += self.bias_h\n",
    "        self.hiden_activation = sigmoid(self.z_hiden_activation)\n",
    "        \n",
    "        self.z_output_activation = np.dot(self.weight_ho, self.hiden_activation)\n",
    "        self.z_output_activation += self.bias_o\n",
    "        self.output_activation = sigmoid(self.z_output_activation)\n",
    "        \n",
    "        return self.output_activation\n",
    "    \n",
    "    def train(self, inputs, labels):\n",
    "        \n",
    "        #Calculate the errors\n",
    "        outputs = self.feedforward(inputs)\n",
    "        output_errors = labels - outputs\n",
    "        hiden_errors = np.dot(self.weight_ho.T, output_errors)\n",
    "        \n",
    "        #Calculate the gradient for output layer\n",
    "        gradients = dsigmoid(outputs)\n",
    "        gradients = gradients * output_errors\n",
    "        gradients = gradients * self.learningRate\n",
    "        \n",
    "        #Calculate deltas for ho weights\n",
    "        weight_ho_deltas = np.dot(gradients, self.hiden_activation.T)\n",
    "\n",
    "        #Adjusting ho weights and bias\n",
    "        self.weight_ho += weight_ho_deltas\n",
    "        self.bias_o += gradients\n",
    "        \n",
    "        #Calculate the gradient for hiden layer\n",
    "        hiden_gradients = dsigmoid(self.hiden_activation)\n",
    "        hiden_gradients = hiden_gradients * hiden_errors\n",
    "        hiden_gradients = hiden_gradients * self.learningRate\n",
    "        \n",
    "        #Calculate deltas for ih weights\n",
    "        weight_ih_deltas = np.dot(hiden_gradients, inputs.T)\n",
    "\n",
    "        #Adjusting ih weights and bias\n",
    "        self.weight_ih += weight_ih_deltas\n",
    "        self.bias_h += hiden_gradients\n",
    "        \n",
    "        return (1/output_errors.shape[0]) * ((output_errors*output_errors).sum())\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        random_list = random.sample(range(0, y_test.shape[0]), y_test.shape[0])\n",
    "        prediction_count = []\n",
    "        for i in random_list:\n",
    "            \n",
    "            prediction = self.feedforward(X_test.values[i].reshape(400,1))\n",
    "            actual = y_test.values[i]\n",
    "            \n",
    "            predicted_value = np.where(prediction == prediction.max())[0][0]\n",
    "            actual_value = np.where(actual == actual.max())[0][0]\n",
    "            \n",
    "            if(predicted_value == actual_value):\n",
    "                prediction_count.append(1)\n",
    "        \n",
    "            else:\n",
    "                prediction_count.append(0)\n",
    "            \n",
    "            np_prediction_count = np.array(prediction_count)\n",
    "            accuracy = np_prediction_count.sum()/np_prediction_count.size\n",
    "            print(str(np_prediction_count.size) + ' / ' + str(y_test.shape[0]), end ='\\r')\n",
    "            \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is up! <br>\n",
    "Now we'll test it on the digits classification usecase <br>\n",
    "To do that we'll use `400` as the number composing the input layer giving that we have 400 pixels in each image. <br>\n",
    "We'll use `10` output nodes as our 10 different possible values <br>\n",
    "We use arbitrary `35` nodes for the hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `sample` method to suffle our data before training our model with all of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3998/3999\tMSE = 0.04777310934412163056\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "n = NeuralNetwork(400, 35, 10)\n",
    "\n",
    "loop = 0\n",
    "\n",
    "l = random.sample(range(0, y_train.shape[0]), y_train.shape[0])\n",
    "\n",
    "for i in l:\n",
    "    curr_img = X_train.values[l[i]].reshape(400,1)\n",
    "    curr_label = y_train.values[l[i]].reshape(10,1)\n",
    "    MSE = n.train(curr_img, curr_label)\n",
    "    print (str(loop) + '/' + str(X_train.shape[0]) + '\\tMSE = ' + str(MSE), end='\\r')\n",
    "    loop = loop+1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `score` method to compute the **accuracy** of our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 / 1000\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.39999999999999"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.score(X_test, y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a different resulting accuracy depending on the shuffle. <br>\n",
    "it fluctuate from 75% to 85% which is prertty good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing our model accuracy to scikit learn's one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn's neural network does not work the same way. <br>\n",
    "Indeed it will feedforward all the datasets before computing the errors. <br>\n",
    "the datasets will be iterated several times.\n",
    "> You can configure this value with `max_iter` attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxence/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=35, learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(35), activation='logistic', solver='adam', max_iter=100 )\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       402\n",
      "           1       0.98      0.96      0.97       394\n",
      "           2       0.98      0.86      0.92       404\n",
      "           3       0.95      0.85      0.90       398\n",
      "           4       0.98      0.90      0.94       395\n",
      "           5       0.95      0.81      0.88       395\n",
      "           6       0.98      0.93      0.96       397\n",
      "           7       0.98      0.91      0.95       405\n",
      "           8       0.95      0.80      0.87       411\n",
      "           9       0.97      0.87      0.92       398\n",
      "\n",
      "   micro avg       0.97      0.89      0.93      3999\n",
      "   macro avg       0.97      0.89      0.93      3999\n",
      "weighted avg       0.97      0.89      0.93      3999\n",
      " samples avg       0.88      0.89      0.88      3999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxence/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_train,predict_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn's neural network model gives us a 97% accuracy score. <br>\n",
    "This value could be explained by the way this neural network train the model as explained above firstly and by the learning rate which is realy low."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
